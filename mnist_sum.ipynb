{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `pyswip` and consult the Prolog background knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyswip import Prolog\n",
    "prolog = Prolog()\n",
    "prolog.consult('mnist_sum.pl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if the `CLP(FD)`-based abduction in the background knowledge base works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 adds 9 equals 10.\n",
      "2 adds 8 equals 10.\n",
      "3 adds 7 equals 10.\n",
      "4 adds 6 equals 10.\n",
      "5 adds 5 equals 10.\n",
      "6 adds 4 equals 10.\n",
      "7 adds 3 equals 10.\n",
      "8 adds 2 equals 10.\n",
      "9 adds 1 equals 10.\n"
     ]
    }
   ],
   "source": [
    "target = 10\n",
    "for soln in prolog.query(\"abduce([X,Y], {})\".format(target)):\n",
    "    print(soln[\"X\"], \"adds\", soln[\"Y\"], \"equals {}.\".format(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abductive Learning\n",
    "\n",
    "Now let's try to implement the MNIST sum learning algorithm using the Abductive Learning framework.\n",
    "\n",
    "### Dataset Generation\n",
    "\n",
    "Directly copy the codes from the `data_generator.ipynb` notebook file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "dataset1 = datasets.MNIST('data', train=True, download=True,\n",
    "                            transform=transform)\n",
    "dataset2 = datasets.MNIST('data', train=False,\n",
    "                            transform=transform)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "digit_groups_train = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]}\n",
    "digit_groups_test = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], 8:[], 9:[]}\n",
    "\n",
    "for i in range(len(dataset1)): \n",
    "    digit_groups_train[int(dataset1.targets[i])].append(i)\n",
    "for i in range(len(dataset2)): \n",
    "    digit_groups_test[int(dataset2.targets[i])].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Sum:\n",
    "    def __init__(self, num, digit_groups):\n",
    "        self.targets = []\n",
    "        self.img_indices = [] # list of lists of 2 ids\n",
    "        self.ground_truth = []\n",
    "        self.length = num\n",
    "        for i in range(num):\n",
    "            # sampling two numbers from 0 to 9\n",
    "            sampled_digits = np.random.choice(10, 2)\n",
    "            self.ground_truth.append(list(sampled_digits))\n",
    "\n",
    "            # using the sum of the sampled digits as the target\n",
    "            self.targets.append(sum(sampled_digits))\n",
    "            ids = []\n",
    "            for j in range(len(sampled_digits)):\n",
    "                # get the j-th digits\n",
    "                digit = sampled_digits[j]\n",
    "                # total number of the images of the digit\n",
    "                ids.append(np.random.choice(digit_groups[digit]))\n",
    "            self.img_indices.append(ids)\n",
    "\n",
    "# Generate the training and test dataset for MNIST Sum task\n",
    "mnist_sum_data_train = MNIST_Sum(3000, digit_groups_train)\n",
    "mnist_sum_data_test = MNIST_Sum(3000, digit_groups_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Machine Learning Part\n",
    "\n",
    "Neural networks for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "def conv_net(outdim, *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, 32, 3, 1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, 3, 1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Dropout(0.25),\n",
    "        Flatten(),\n",
    "        nn.Linear(9216, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(128, outdim),\n",
    "        nn.LogSoftmax(dim=1)\n",
    "    )\n",
    "\n",
    "\n",
    "def auto_enc(outdim, *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(outdim, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 784)\n",
    "    )\n",
    "\n",
    "\n",
    "def mlp(indim, outdim, *args, **kwargs):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(indim, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, outdim),\n",
    "        nn.LogSoftmax(dim=1),\n",
    "    )\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    \"\"\"A (Bi)LSTM Model.\n",
    "\n",
    "    Attributes:\n",
    "        num_layers: the number of LSTM layers (number of stacked LSTM models) in the network.\n",
    "        in_dim: the size of the input sample.\n",
    "        hidden_dim: the size of the hidden layers.\n",
    "        out_dim: the size of the output.\n",
    "        activation: the activation function.\n",
    "        bidirectional: the flag for bidirectional LSTM\n",
    "        dropout: the dropout rate if num_layers > 1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_layers, in_dim, hidden_dim, out_dim,\n",
    "                 bidirectional=False, dropout=0):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.lstm = nn.LSTM(self.in_dim,\n",
    "                            self.hidden_dim,\n",
    "                            num_layers=self.num_layers,\n",
    "                            bidirectional=self.bidirectional,\n",
    "                            dropout=self.dropout,\n",
    "                            batch_first=True)\n",
    "        fc_dim = self.hidden_dim * 2 if self.bidirectional else self.hidden_dim\n",
    "        self.fc = nn.Linear(fc_dim, self.out_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        lstm_out, _ = self.lstm(inputs)\n",
    "        outputs = self.fc(lstm_out[:, -1, :])\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def loss_function(self, pred, y):\n",
    "        return F.binary_cross_entropy(pred, y.view(y.shape[0], -1))\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    outdim = 10\n",
    "\n",
    "    def __init__(self, outdim):\n",
    "        super(Net, self).__init__()\n",
    "        self.outdim = outdim\n",
    "        self.enc = conv_net(outdim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.enc(x)\n",
    "        return output\n",
    "\n",
    "    def loss_function(self, pred, y):\n",
    "        return F.nll_loss(pred, y)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch,\n",
    "          log_interval=1000, dry_run=False):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = model.loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if dry_run:\n",
    "                break\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += model.loss_function(output, target).item()\n",
    "            # get the index of the max log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('-- Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Logic Abduction Part\n",
    "\n",
    "It involves the following steps:\n",
    "1. Given the target (label, i.e., the sum of the two images), using `pyswip` to abduce possible pseudo-labels for them.\n",
    "2. Calculate the probability of each pair of pseudo-labels.\n",
    "3. Return the most probable pseudo-labels to retrain the neural network.\n",
    "\n",
    "_Remark_: For more complicated problems, a better way of searching for the best pseudo-labels is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Abducing possible pseudo-labels given the sum\n",
    "\n",
    "- `pl` is the Prolog instance that consulted `mnist_sum.pl`;\n",
    "- `target` is the sum of two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abduce(pl, target):\n",
    "    # This abduce/2 function is defined in \"mnist_sum.pl\"\n",
    "    ans = [];\n",
    "    for soln in pl.query(\"abduce([X,Y], {})\".format(target)): # given targer, abduce X and Y\n",
    "        ans.append([soln[\"X\"], soln[\"Y\"]])\n",
    "    if len(ans) > 0:\n",
    "        return ans\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the `abduce` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(abduce(prolog, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Abductive Learning Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing useful libraries and set the default neural network training parameters within the Abductive Learning Process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "nn_train_kwargs = {'batch_size': 64, 'shuffle': True}\n",
    "nn_epoch = 2\n",
    "\n",
    "\n",
    "nn_test_loader = torch.utils.data.DataLoader(dataset2, **nn_train_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions for abduction:\n",
    "1. `get_mnist_imgs`: given `indices`, sample a subset of images from `dataset` (such as the `MNIST` dataset).\n",
    "2. `best_pseudo_label`: given a set of abduced possible pseudo-labels and the pseudo-label distribution, return the most probable pseudo-label combination for each image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_imgs(dataset, indices, use_cuda=False):\n",
    "    \"\"\"\n",
    "    Get the image tensor from mnist dataset by indices\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(indices)\n",
    "    img_tensor, tgt = dataset[indices[0]]\n",
    "    img_tensor = torch.reshape(img_tensor, (1, 1, 28, 28))\n",
    "    targets = [tgt]\n",
    "    i = 1\n",
    "    while i < n:\n",
    "        img, tgt = dataset[indices[i]]\n",
    "        img = torch.reshape(img, (1, 1, 28, 28))\n",
    "        img_tensor = torch.cat((img_tensor, img), 0)\n",
    "        targets.append(tgt)\n",
    "        i = i + 1\n",
    "    if use_cuda:\n",
    "        img_tensor = img_tensor.to(torch.device(\"cuda\"))\n",
    "    return img_tensor, targets # list of image tensors and list of its targets\n",
    "\n",
    "def best_pseudo_label(pseudo_label_lists, pseudo_label_dist):\n",
    "    \"\"\"\n",
    "    Given plabel lists and plabel distribution list\n",
    "    Return the best combination with score\n",
    "    \"\"\"\n",
    "    best_score = -100000.0\n",
    "    best_combi = np.zeros(pseudo_label_dist.shape[0])\n",
    "    probabilities = np.exp(pseudo_label_dist)\n",
    "    for label_combi in pseudo_label_lists:\n",
    "        # because the scores are log_softmax, the log probability can be calculated as sum\n",
    "        score = 1.0\n",
    "        for j in range(len(label_combi)):\n",
    "            score = score*probabilities[j, label_combi[j]]\n",
    "        if score >= best_score:\n",
    "            best_score = score\n",
    "            best_combi = label_combi\n",
    "    return best_combi, score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main procedure for abductive Learning. Given a machine learning `model` and a prolog instance `pl` with `dataset`, it does the following steps:\n",
    "1. Using `model` to predict the pseudo-label probabilistic distribution of `dataset`;\n",
    "2. Finding the best pseudo-label combination considering both the abduction result from `pl` and the pseudo-label probabilistic distribution;\n",
    "3. Retrain the neural network with the abduced pseudo-labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ABL_main(model, pl, dataset, optimizer=None, scheduler=None):\n",
    "    # number of examples\n",
    "    num_examples = dataset.length\n",
    "    abduced_data_ids = [] # list of ids\n",
    "    abduced_labels = [] # list of labels\n",
    "    ground_truth_labels = [] # list of targets\n",
    "\n",
    "    # start abduction\n",
    "    for i in tqdm (range(num_examples), desc=\"Abducing...\"):\n",
    "        target = int(dataset.targets[i])\n",
    "        possible_pseudo_labels = abduce(pl, target) # given target, generate possible pseudo labels\n",
    "        if possible_pseudo_labels is not None:\n",
    "            # reshape the tensor of the two MNIST images to match NN model's input dimensions\n",
    "            img_indices = dataset.img_indices[i] # get the ids for the two images\n",
    "            imgs, _ = get_mnist_imgs(dataset1, img_indices, use_cuda=False) # get the two img tensors\n",
    "\n",
    "            pseudo_label_distribution = model(imgs).detach().numpy() # the Net\n",
    "\n",
    "            # find the pseudo-labels with the maximum likelihood\n",
    "            abduced_pseudo_labels, _ = best_pseudo_label(possible_pseudo_labels, pseudo_label_distribution)\n",
    "\n",
    "            # for abduced dataset\n",
    "            abduced_data_ids = abduced_data_ids + img_indices\n",
    "\n",
    "            abduced_labels = abduced_labels + abduced_pseudo_labels\n",
    "            ground_truth_labels = ground_truth_labels + dataset.ground_truth[i]\n",
    "\n",
    "    # changing the training data labels to the abduced labels\n",
    "    for i, img in enumerate(abduced_data_ids):\n",
    "        dataset1.targets[img] = abduced_labels[i]\n",
    "    \n",
    "    abduction_accuracy = np.sum(np.array(ground_truth_labels) == np.array(abduced_labels))/len(abduced_labels)\n",
    "\n",
    "\n",
    "    # making new dataset with abduced labels\n",
    "    abduced_data = torch.utils.data.Subset(dataset1, abduced_data_ids)\n",
    "\n",
    "    # training the neural network model\n",
    "    abduced_train_loader = torch.utils.data.DataLoader(abduced_data, batch_size=64)\n",
    "    \n",
    "\n",
    "    for epoch in range(1, nn_epoch + 1):\n",
    "        train(model, device, abduced_train_loader, optimizer, epoch)\n",
    "        print(\"Abduction accuracy: \", abduction_accuracy)\n",
    "        scheduler.step()\n",
    "    test(model, device, nn_test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise model and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_sum_data_train.targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [5]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "img_indices = mnist_sum_data_train.img_indices[0] # get the ids for the two images\n",
    "imgs, _ = get_mnist_imgs(dataset1, img_indices, use_cuda=False) # get the two img tensors\n",
    "# Plot them\n",
    "_, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(dataset1.data[img_indices[0], :, :])\n",
    "axs[1].imshow(dataset1.data[img_indices[1], :, ])\n",
    "pseudo_label_distribution = model(imgs).detach().numpy() # the Net\n",
    "\n",
    "\n",
    "print(model(imgs).argmax(dim=1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_pseudo_labels = abduce(prolog, 6) # given target, generate possible pseudo labels\n",
    "pseudo_label_distribution = model(imgs).detach().numpy() # the Net\n",
    "abduced_pseudo_labels, _ = best_pseudo_label(possible_pseudo_labels, pseudo_label_distribution)\n",
    "abduced_pseudo_labels\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(outdim=10).to(device)\n",
    "\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, nn_epoch + 1):\n",
    "        normaltrain = torch.utils.data.DataLoader(dataset1, batch_size=64)\n",
    "        train(model, device, normaltrain, optimizer, epoch)\n",
    "        scheduler.step()\n",
    "        test(model, device, nn_test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run Abductive Learning without any pre-train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:32<00:00, 91.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 2.258973\n",
      "Abduction accuracy:  0.22833333333333333\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 2.106419\n",
      "Abduction accuracy:  0.22833333333333333\n",
      "-- Test set: Average loss: 0.0327, Accuracy: 2969/10000 (30%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:31<00:00, 95.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 1.802510\n",
      "Abduction accuracy:  0.438\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 1.359203\n",
      "Abduction accuracy:  0.438\n",
      "-- Test set: Average loss: 0.0220, Accuracy: 4786/10000 (48%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:28<00:00, 106.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 1.242864\n",
      "Abduction accuracy:  0.6496666666666666\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 1.289982\n",
      "Abduction accuracy:  0.6496666666666666\n",
      "-- Test set: Average loss: 0.0124, Accuracy: 7156/10000 (72%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:31<00:00, 94.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.956407\n",
      "Abduction accuracy:  0.8726666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.751012\n",
      "Abduction accuracy:  0.8726666666666667\n",
      "-- Test set: Average loss: 0.0057, Accuracy: 9076/10000 (91%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:32<00:00, 92.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.592407\n",
      "Abduction accuracy:  0.9776666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.539589\n",
      "Abduction accuracy:  0.9776666666666667\n",
      "-- Test set: Average loss: 0.0033, Accuracy: 9448/10000 (94%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:32<00:00, 93.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.362854\n",
      "Abduction accuracy:  0.9923333333333333\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.447820\n",
      "Abduction accuracy:  0.9923333333333333\n",
      "-- Test set: Average loss: 0.0029, Accuracy: 9531/10000 (95%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:31<00:00, 95.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.480746\n",
      "Abduction accuracy:  0.9943333333333333\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.360771\n",
      "Abduction accuracy:  0.9943333333333333\n",
      "-- Test set: Average loss: 0.0027, Accuracy: 9558/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:33<00:00, 90.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.297648\n",
      "Abduction accuracy:  0.995\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.457465\n",
      "Abduction accuracy:  0.995\n",
      "-- Test set: Average loss: 0.0027, Accuracy: 9562/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:32<00:00, 91.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.478222\n",
      "Abduction accuracy:  0.9953333333333333\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.415555\n",
      "Abduction accuracy:  0.9953333333333333\n",
      "-- Test set: Average loss: 0.0027, Accuracy: 9567/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:30<00:00, 99.86it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.388577\n",
      "Abduction accuracy:  0.9953333333333333\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.490199\n",
      "Abduction accuracy:  0.9953333333333333\n",
      "-- Test set: Average loss: 0.0026, Accuracy: 9566/10000 (96%)\n"
     ]
    }
   ],
   "source": [
    "ABL_epochs = 5\n",
    "for epoch in range(ABL_epochs):\n",
    "    ABL_main(model, prolog, mnist_sum_data_train, optimizer=optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run Abductive Learning with one-shot pre-train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample an one-shot training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/10 (0%)]\tLoss: 2.337119\n",
      "Train Epoch: 2 [0/10 (0%)]\tLoss: 2.096287\n",
      "Train Epoch: 3 [0/10 (0%)]\tLoss: 1.946862\n",
      "Train Epoch: 4 [0/10 (0%)]\tLoss: 1.636731\n",
      "-- Test set: Average loss: 0.0306, Accuracy: 3867/10000 (39%)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# reset the machine learning model\n",
    "model = Net(outdim=10).to(device)\n",
    "\n",
    "# reset dataset1 to reset the labels for one-shot training, \n",
    "# since the previous abductive learning process has changed \n",
    "# the ground truth labels in dataset1\n",
    "dataset1 = datasets.MNIST('data', train=True, download=True,\n",
    "                            transform=transform)\n",
    "\n",
    "n_samples = 1\n",
    "few_shot_indices = []\n",
    "\n",
    "for i in range(10):\n",
    "    few_shot_indices = few_shot_indices + \\\n",
    "        random.sample(digit_groups_train[i], n_samples)\n",
    "\n",
    "# few_shot_indices = random.sample(all_img_indices, n_samples)\n",
    "\n",
    "sup_imgs_train = torch.utils.data.Subset(dataset1, few_shot_indices)\n",
    "\n",
    "sup_train_loader = torch.utils.data.DataLoader(\n",
    "    sup_imgs_train, **nn_train_kwargs)\n",
    "\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "for epoch in range(1, 5):\n",
    "    train(model, device, sup_train_loader,\n",
    "        optimizer, epoch)\n",
    "    #test(model, device, nn_test_loader)\n",
    "    scheduler.step()\n",
    "test(model, device, nn_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:30<00:00, 97.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 1.958068\n",
      "Abduction accuracy:  0.6456666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 1.296085\n",
      "Abduction accuracy:  0.6456666666666667\n",
      "-- Test set: Average loss: 0.0137, Accuracy: 7669/10000 (77%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:29<00:00, 101.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.926988\n",
      "Abduction accuracy:  0.9103333333333333\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.585736\n",
      "Abduction accuracy:  0.9103333333333333\n",
      "-- Test set: Average loss: 0.0046, Accuracy: 9210/10000 (92%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:30<00:00, 99.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.608485\n",
      "Abduction accuracy:  0.9873333333333333\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.344015\n",
      "Abduction accuracy:  0.9873333333333333\n",
      "-- Test set: Average loss: 0.0027, Accuracy: 9508/10000 (95%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:29<00:00, 101.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.331251\n",
      "Abduction accuracy:  0.995\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.349095\n",
      "Abduction accuracy:  0.995\n",
      "-- Test set: Average loss: 0.0024, Accuracy: 9554/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:29<00:00, 100.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.333204\n",
      "Abduction accuracy:  0.9953333333333333\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.350591\n",
      "Abduction accuracy:  0.9953333333333333\n",
      "-- Test set: Average loss: 0.0023, Accuracy: 9561/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:29<00:00, 101.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.193948\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.240049\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0023, Accuracy: 9576/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:29<00:00, 101.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.218380\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.282037\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0022, Accuracy: 9574/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:29<00:00, 101.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.307142\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.427967\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0022, Accuracy: 9578/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:29<00:00, 101.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.305546\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.310958\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0022, Accuracy: 9580/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:29<00:00, 102.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.294766\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.306095\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0022, Accuracy: 9579/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:29<00:00, 100.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.367064\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.403212\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0022, Accuracy: 9579/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:29<00:00, 100.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.338030\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.229107\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0022, Accuracy: 9579/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:30<00:00, 99.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.222177\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.232248\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0022, Accuracy: 9579/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:29<00:00, 100.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.355552\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.440173\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0022, Accuracy: 9579/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:30<00:00, 99.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.301352\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.249726\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0022, Accuracy: 9579/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:20<00:00, 145.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.252311\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.270329\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0023, Accuracy: 9579/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:26<00:00, 114.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.370963\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.205726\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0022, Accuracy: 9579/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:28<00:00, 104.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.236914\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.317033\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0022, Accuracy: 9579/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:19<00:00, 152.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.265046\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.282606\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0022, Accuracy: 9579/10000 (96%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Abducing...: 100%|██████████| 3000/3000 [00:17<00:00, 170.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/6000 (0%)]\tLoss: 0.353039\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "Train Epoch: 2 [0/6000 (0%)]\tLoss: 0.300775\n",
      "Abduction accuracy:  0.9956666666666667\n",
      "-- Test set: Average loss: 0.0022, Accuracy: 9579/10000 (96%)\n"
     ]
    }
   ],
   "source": [
    "ABL_epochs = 20\n",
    "for epoch in range(ABL_epochs):\n",
    "    ABL_main(model, prolog, mnist_sum_data_train, optimizer=optimizer, scheduler=scheduler) #check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0818a47565ceb6402158bbf0dc496aa25facf52e7106c9c4cd712582e3748063"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
